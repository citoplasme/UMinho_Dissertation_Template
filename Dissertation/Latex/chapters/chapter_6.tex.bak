\chapter{Conclusions and Future Work}
\label{chap:chap6}
In this last chapter, we summarize the developed work throughout this dissertation's year, as well as the main contributions from each proposal. Additionally, we present some key points that should be studied in the future, in order to enhance the stroke lesion outcome prediction.


The main goal of this dissertation comprised the improvement of ischemic stroke lesion outcome prediction in a 90-day follow-up through the development of an automated algorithm, capable of distinguishing correctly the background voxels from the lesions' voxels, given certain \acrshort{mri} modalities standard perfusion and diffusion maps, and \acrshort{4d} \acrshort{pwi} data. The development of a robust stroke lesion prediction algorithm is of high relevance, since nowadays the delineation of the lesion is still performed manually, which is time consuming and prone to errors. More recently, various automated algorithms have been developed with great progress being made across time. Yet, none has been capable of producing reliable results until now \cite{winzeck2018isles}.

In this work, we began by studying the effect of altering the number of filters along a U-Net structure from 32/64/128 to 40/80/160, with the standard parametric maps as its input. The filters' proportion of 32/64/128 had been previously employed by other authors \cite{pinto}. However, we found the 40/80/160 proportion to be more beneficial with the chosen regularization, although both attained similar performances when evaluated on the Challenge dataset.

Then, we analyzed the importance of applying data augmentation mechanisms in the ischemic stroke lesion outcome prediction. To that extent, several tests were conducted, from not employing any kind of data augmentation method, to applying two different sets of rotation angles that would be applied over the $90\textdegree$ rotations proposed on the baseline model. It was possible to see through this study that the standard $90\textdegree$ rotations had a crucial role in this problem, as the Training dataset used in all the developed work provided a low amount of cases of patients with stroke. In addition, we were able to achieve a better performance with a better balance between precision and recall by employing a range of rotation angles, in comparison to the one obtained with the baseline model. Although the approach where we added a population of four extra angles did not allow to perceive its added value in the baseline architecture, the opposite was verified in some other tests, such as the case where we replaced the regular U-Net structure for a cascade of dilated convolutional U-blocks. Based on all the different tests conducted with different data augmentation mechanisms, it is not possible to claim with all certainty which approach is best suited for this problem. However, we can affirm that the $90\textdegree$ rotations do aid the lesion prediction and should, therefore, be employed. Regarding other approaches that employ different rotation angles, we may only claim that their usage is not unreasonable, but the best results depend on the network's structure and on the used dataset. Nonetheless, we were able to prove the relevance of these methods to create more data variability, when using small datasets.

Afterwards, a study regarding the expansion of the context by employing dilated convolutions was performed. The aim of this study consisted of replacing the U-Net for a dilated U-block with increasing dilation factors at its bottleneck, so that the network could see more lesion context. Although several studies have shown that this kind of approach does improve the network's learning and consequent performance, we verified the opposite when resorting to all training subjects. In fact, even when a cascade of this new structure was employed, without extra data augmentation methods included, the overall performance of the network did not improve. Only when we removed some of the training subjects, the dilated convolutional network provided an overall increase of the performance of the model. The reasoning behind this phenomenon might be sustained by the fact those four training stroke subjects, containing small to medium-sized lesions, consisted of such complex cases that the network struggled in learning their features with such expansion of context. However, this issue was attenuated with the inclusion of extra rotation angles, although the network's performance never surpassed the baseline's. For these reasons, we suggest a deeper exploration on the cascade model, specially in terms of tuning the weights of the losses.

Additionally, we presented two strategies for multiple data branches' combination with the first involving the application of segmentation \acrshort{se} blocks when merging feature sets retrieved from the processed \acrshort{pwi} data and standard parametric maps, and the second one comprising data fusion at different levels of the network. In the former approach, we employed and compared different segmentation \acrshort{se} blocks, previously developed by other authors, to our proposal, which consisted of an upgraded version of the \acrshort{segse} block \cite{pereira}. In this study, we verified that the best approach to further emphasize the most informative features consisted of our proposal, due to the implementation of depthwise separable convolutions, instead of regular ones. This substitution allowed not only a reduction on the number of parameters involved, but also a better Precision-Recall proportion, as well as lower distance metrics. In the future, the inclusion of this attention block on other locations of the network should be studied, since it could possibly allow the retrieval of more discriminative features at higher levels of the model.

The new information merging approach consisted of multiple data fusions, two before and one after the \acrshort{2d} U-Nets. Not only that, but we also processed temporally the data-driven \acrshort{pwi} in order to produce features encoding the bolus passage information. Additionally, the standard maps were also preprocessed to generate more complex features. Here, we verified the best approach to be the one encompassing the standard maps as its input, with a channels' proportion of 40/80/160 and a preprocessing block comprising a convolutional block with a residual connection. Several other strategies were developed. Nonetheless, there is still room for improvement in different aspects of the learning phase (e.g. the sampler). Although it was not capable of achieving the best performance, the complete structure with a filters' proportion of 32/64/128 achieved competitive results, taking into account the state of the art ones. Yet, we believe that with further fine-tunning one could increase the overall performance. In fact, we believe that the addition of the data-driven \acrshort{pwi} to the standard maps processing can be useful. Nonetheless, the underlying phenomena occurring across time and the amount of data available refrained us from proving with robustness the added value of our proposal. As future work, one could perform a deeper investigation on this fusion approach in order to achieve the best hyperpameters values, namely the regularization, the number of input samples, the used sampler, the number of channels, among others. 

The last study comprised the combination of supervised and unsupervised learning algorithms. There, we employed the \acrshort{vae} block, with several variations, on the dilated convolutional cascade network, in order to compensate the low amount of training data. This analysis allowed us to verify that the \acrshort{vae}, with the standard maps as its input, is capable of providing useful information to enhance the lesions' evolution prediction, but, in the developed work, it was not capable of surpassing its own baseline model. Nevertheless, this might have been due to a series of chosen hyperparameters, such as the number of dilated convolutions with increasing dilation ratios in the probabilistic encoder, the weights applied to each loss, the latent dimension value, the optimizer or even the learning rate value. Therefore, we point out the validation of these key points to further improve the results in the future. Additionally, the implementation of the best \acrshort{vae} block, with the data-driven \acrshort{pwi} reconstructing the standard parametric maps, allowed the model to reach a state of the art competitive performance while improving the Precision-Recall balance. Although this variant was not capable of surpassing the baseline performance, we believe that this subject should be considered in further approaches to characterize well the latent space of the data, which ultimately translated to a higher capability to predict the final stroke lesion.

Although the achieved performances possess low scores, they are competitive to other state of the art methodologies. Furthermore, taking into account that the Dice score of the manually delineated lesions is $ 0.58 \pm 0.20 $ \cite{winzeck2018isles}, these automated methods performed reasonably well. This low accuracy, however, is due to the fact that the provided databases do not contain all the information used to assess the evolution of the lesions, which most clinicians resort to. Therefore, lacking this kind of data, it is not possible to produce robust predictions, capable of surpassing the work of a clinician, yet. Nevertheless, most of the results obtained in this work are great improvements in the context of the lesion prediction when compared to the submissions on \acrshort{isles} Challenge 2017, with our best approaches currently ranking first and second in terms of Dice score.